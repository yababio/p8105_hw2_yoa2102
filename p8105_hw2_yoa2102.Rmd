---
title: "Homework 2"
output: github_document
---
```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1



##### Read the Mr. Trash Wheel dataset into R.

```{r read_trashwheel}
trashwheel_df =
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```



##### Read and clean the precipitation data for 2018.

```{r read_precip_2018}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
```

##### Read and clean the precipitation data for 2017.
```{r read_precip_2017}
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```


##### Now combine the annual precipitation data frames (2017 and 2018). 
```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_month_name_df = 
  left_join(precip_df, month_df, by = "month") %>%
  relocate(year, month, month_name)
```


##### Describe the Mr. Trash Wheel and Precipitation datasets.
This data set contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the harbor, it is collected by the trashwheel and stored in a dumpster. The dataset contains information about the month, year, day, and type of trash collected. The dataset consists of `r nrow(trashwheel_df)` rows and `r ncol(trashwheel_df)` columns. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2019 was `r trashwheel_df %>% filter(year == 2019) %>% pull(sports_balls) %>% median()`.

* The average weight of the trash collected by the trashwheel in 2019 was `r round(trashwheel_df %>% filter(year == 2019) %>% pull(weight_tons) %>% mean(), 2)` tons. 

The 2017 and 2018 Precipitation datasets each have `r ncol(precip_2018)` columns and `r nrow(precip_2018)` rows. The combined Precipitation dataset has `r ncol(precip_month_name_df)` columns and `r nrow(precip_month_name_df)` rows. 

* The total precipitation in 2017 was `r sum(pull(precip_2017, total))` inches.

* The total precipitation in 2018 was `r sum(pull(precip_2018, total))` inches.

## Problem 2

##### Read and clean the NYC Transit data.

```{r read_transit}
transit_df =
  read_csv(
     "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE))
 
```

##### Describe the NYC Transit data.
The NYC Transit dataset contains information about the lines, routes available, entrance types, vending availability, and ADA compliance of subway stations in New York City.
This dataset consists of `r ncol(transit_df)` columns and `r nrow(transit_df)` rows. 

In order to clean the dataset thus far, variable names were standardized using `janitor::clean_names()`. Using `select`, the following relevant variables were kept from the original dataset: `r colnames(transit_df)`. Lastly, the `entry` variable was converted from a character to a logical variable using the functions `mutate` and `recode`.

However, it is important to note that these data are NOT tidy. The route1:route11 variables make the dataset uneccessarily wide, and generate a large number of NAs. In order to optimize the dataset, it would be best to reformat these variables and their contents as observations within new variables (route_name and route_number).  


##### How many distinct stations are there?
```{r distinct_stations}
distinct_stations = distinct(transit_df, station_name, line)
```
There are `r nrow(distinct_stations)` distinct stations in NYC.

##### How many stations are ADA compliant?
```{r ada_compliant}
ada_compliant = distinct(transit_df, station_name, line, ada) %>%
  filter(ada == TRUE)
```
There are `r nrow(ada_compliant)` ADA compliant stations in NYC.

##### What proportions of station entrances/exits without vending allow entrance?
```{r vending_entrance}
without_vending = filter(transit_df, vending == "NO")

allow_entrance = filter(without_vending, entry == TRUE)
```
The proportion of station entrances/exits without vending that allow entrance is `r round(nrow(allow_entrance)/nrow(without_vending), 3)`.



##### Reformat the route and route name variables.
Next, reformat the data so that route number and route name are distinct variables.
```{r reformat_route}
transit_df_tidy =
  transit_df %>%
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_number")

head(transit_df_tidy)
  
```

##### How many distinct stations serve the A train?
```{r distinct_a}
distinct_a = distinct(transit_df_tidy, line, station_name, route_name, .keep_all = TRUE) %>%
  filter(route_number == "A")
```
There are `r nrow(distinct_a)` distinct stations that serve the A train in NYC.


##### Of the stations that serve the A train, how many are ADA compliant?
```{r}
ada_compliant_a = filter(distinct_a, ada == TRUE)
```
Of the stations that serve the A train, there are `r nrow(ada_compliant_a)` stations that are ADA compliant.

## Problem 3

##### Read and clean the pols-month dataset.
```{r load_clean_pols}
pols_df =
   read_csv(
     "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(month = month.abb[as.numeric(month)],
         president = case_when(
            prez_gop == 0 ~ "dem",
            prez_gop == 1 ~ "gop",
            prez_gop == 2 ~ "gop"),
         year = as.numeric(year)) %>%
  select(-prez_dem, -prez_gop, -day)

```

##### Read and clean the snp dataset. 
```{r load_clean_snp}
snp_df =
   read_csv(
     "./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
  mutate(
    month = month.abb[as.numeric(month)],
    year = as.numeric(year)) %>%
  select(-day) %>%
  relocate(year, month)
   
```


##### Read and clean the unemployment dataset.
```{r load_clean_unemployment}
unemployment_df =
   read_csv(
     "./data/fivethirtyeight_datasets/unemployment.csv") %>%
   pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate") %>%
  rename(year = Year)
  
  
```



##### Join the pols-month, snp, and unemployment datasets.
```{r merge_data}
first_join = 
  left_join(pols_df, snp_df, by = c("year", "month")) 

final_df = 
  left_join(first_join, unemployment_df, by = c("year", "month")) 
  
```

##### Describe the pols-month, snp, unemployment, and final combined datasets.
The pols-month dataset contains information about the number of national politicians (presidents, senators, representatives) who are democratic or republican at any given point in time.The data collected spans from Jan 1947 to Jun 2015. After cleaning, this dataset consisted of `r ncol(pols_df)` columns and `r nrow(pols_df)` rows.

The snp dataset contains information related to Standard & Poorâ€™s stock market index (S&P). After cleaning, this dataset consisted of `r ncol(snp_df)` columns and `r nrow(snp_df)` rows.The data collected spans from Jan 1950 to Jul 2015.

The unemployment dataset contains information about the (monthly) US unemployment rate from Jan 1948 to Dec 2015. After cleaning, this dataset consisted of `r ncol(unemployment_df)` columns and `r nrow(unemployment_df)` rows.

The final combined dataset consists of `r nrow(final_df)` rows and `r ncol(final_df)` columns. This dataset spans from 1947-2015 and provides information about national politicians and their political affliations, the S&P closing index, and unemployment rate. It consists of the following variables: `r ls(final_df)`.