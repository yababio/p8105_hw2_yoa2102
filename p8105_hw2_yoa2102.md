Homework 2
================

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

##### Read the Mr. Trash Wheel dataset into R.

``` r
trashwheel_df =
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

##### Read and clean the precipitation data for 2018.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
```

##### Read and clean the precipitation data for 2017.

``` r
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

##### Now combine the annual precipitation data frames (2017 and 2018).

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_month_name_df = 
  left_join(precip_df, month_df, by = "month") %>%
  relocate(year, month, month_name)
```

##### Describe the Mr. Trash Wheel and Precipitation datasets.

This data set contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the harbor, it is
collected by the trashwheel and stored in a dumpster. The dataset
contains information about the month, year, day, and type of trash
collected. The dataset consists of 344 rows and 14 columns. Additional
data sheets include month precipitation data. In this dataset:

  - The median number of sports balls found in a dumpster in 2019 was
    8.5.

  - The average weight of the trash collected by the trashwheel in 2019
    was 3.08 tons.

The 2017 and 2018 Precipitation datasets each have 3 columns and 12
rows. The combined Precipitation dataset has 4 columns and 24 rows.

  - The total precipitation in 2017 was 32.93 inches.

  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

##### Read and clean the NYC Transit data.

``` r
transit_df =
  read_csv(
     "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

##### Describe the NYC Transit data.

The NYC Transit dataset contains information about the lines, routes
available, entrance types, vending availability, and ADA compliance of
subway stations in New York City. This dataset consists of 19 columns
and 1868 rows.

In order to clean the dataset thus far, variable names were standardized
using `janitor::clean_names()`. Using `select`, the following relevant
variables were kept from the original dataset: line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11,
entrance\_type, entry, vending, ada. Lastly, the `entry` variable was
converted from a character to a logical variable using the functions
`mutate` and `recode`.

However, it is important to note that these data are NOT tidy. The
route1:route11 variables make the dataset uneccessarily wide, and
generate a large number of NAs. In order to optimize the dataset, it
would be best to reformat these variables and their contents as
observations within new variables (route\_name and route\_number).

##### How many distinct stations are there?

``` r
distinct_stations = distinct(transit_df, station_name, line)
```

There are 465 distinct stations in NYC.

##### How many stations are ADA compliant?

``` r
ada_compliant = distinct(transit_df, station_name, line, ada) %>%
  filter(ada == TRUE)
```

There are 84 ADA compliant stations in NYC.

##### What proportions of station entrances/exits without vending allow entrance?

``` r
without_vending = filter(transit_df, vending == "NO")

allow_entrance = filter(without_vending, entry == TRUE)
```

The proportion of station entrances/exits without vending that allow
entrance is 0.377.

##### Reformat the route and route name variables.

Next, reformat the data so that route number and route name are distinct
variables.

``` r
transit_df_tidy =
  transit_df %>%
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_number")

head(transit_df_tidy)
```

    ## # A tibble: 6 x 10
    ##   line  station_name station_latitude station_longitu… entrance_type entry
    ##   <chr> <chr>                   <dbl>            <dbl> <chr>         <lgl>
    ## 1 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## 2 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## 3 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## 4 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## 5 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## 6 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ## # … with 4 more variables: vending <chr>, ada <lgl>, route_name <chr>,
    ## #   route_number <chr>

##### How many distinct stations serve the A train?

``` r
distinct_a = distinct(transit_df_tidy, line, station_name, route_name, .keep_all = TRUE) %>%
  filter(route_number == "A")
```

There are 60 distinct stations that serve the A train in NYC.

##### Of the stations that serve the A train, how many are ADA compliant?

``` r
ada_compliant_a = filter(distinct_a, ada == TRUE)
```

Of the stations that serve the A train, there are 17 stations that are
ADA compliant.

## Problem 3

##### Read and clean the pols-month dataset.

``` r
pols_df =
   read_csv(
     "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(month = month.abb[as.numeric(month)],
         president = case_when(
            prez_gop == 0 ~ "dem",
            prez_gop == 1 ~ "gop",
            prez_gop == 2 ~ "gop"),
         year = as.numeric(year)) %>%
  select(-prez_dem, -prez_gop, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

##### Read and clean the snp dataset.

``` r
snp_df =
   read_csv(
     "./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
  mutate(
    month = month.abb[as.numeric(month)],
    year = as.numeric(year)) %>%
  select(-day) %>%
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

##### Read and clean the unemployment dataset.

``` r
unemployment_df =
   read_csv(
     "./data/fivethirtyeight_datasets/unemployment.csv") %>%
   pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate") %>%
  rename(year = Year)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

##### Join the pols-month, snp, and unemployment datasets.

``` r
first_join = 
  left_join(pols_df, snp_df, by = c("year", "month")) 

final_df = 
  left_join(first_join, unemployment_df, by = c("year", "month")) 
```

##### Describe the pols-month, snp, unemployment, and final combined datasets.

The pols-month dataset contains information about the number of national
politicians (presidents, senators, representatives) who are democratic
or republican at any given point in time.The data collected spans from
Jan 1947 to Jun 2015. After cleaning, this dataset consisted of 9
columns and 822 rows.

The snp dataset contains information related to Standard & Poor’s stock
market index (S\&P). After cleaning, this dataset consisted of 3 columns
and 787 rows.The data collected spans from Jan 1950 to Jul 2015.

The unemployment dataset contains information about the (monthly) US
unemployment rate from Jan 1948 to Dec 2015. After cleaning, this
dataset consisted of 3 columns and 816 rows.

The final combined dataset consists of 822 rows and 11 columns. This
dataset spans from 1947-2015 and provides information about national
politicians and their political affliations, the S\&P closing index, and
unemployment rate. It consists of the following variables: close,
gov\_dem, gov\_gop, month, president, rep\_dem, rep\_gop, sen\_dem,
sen\_gop, unemployment\_rate, year.
